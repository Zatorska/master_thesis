{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wgrywanie bibliotek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from tbats import TBATS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ustawienia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output folders to save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the current folder where the notebook is located\n",
    "current_folder = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "images_output_folder = os.path.join(current_folder, \"../02_paper/out_figures/\")\n",
    "tables_output_folder = os.path.join(current_folder, \"../02_paper/out_tables/\")\n",
    "models_output_folder = os.path.join(current_folder, \"../../models/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wgranie danych\n",
    "* Get the path to the \"data.zip\" file\n",
    "* Unpacking the file\n",
    "* Uploading the CSV (both: **_data_** and **_data_dict_**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the \"data\" folder inside the repository\n",
    "data_folder = os.path.join(current_folder, \"..\", \"00_data\")\n",
    "\n",
    "# Get the path to the \"data.zip\" file inside the \"data\" folder\n",
    "data_zip_path = os.path.join(data_folder, \"data.zip\")\n",
    "\n",
    "# Check if both entsoe_country_file and entsoe_country_dict_file exist in the target location\n",
    "entsoe_country_file = os.path.join(data_folder, \"entsoe_country.csv\")\n",
    "entsoe_country_dict_file = os.path.join(data_folder, \"entsoe_country_dict.csv\")\n",
    "\n",
    "if not (os.path.exists(entsoe_country_file) and os.path.exists(entsoe_country_dict_file)):\n",
    "    # Extract the data.zip file\n",
    "    with zipfile.ZipFile(data_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_folder)\n",
    "    \n",
    "# Read the CSV files and create DataFrames\n",
    "data = pd.read_csv(entsoe_country_file, sep=';')\n",
    "data_dict = pd.read_csv(entsoe_country_dict_file, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation (part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "\n",
    "# Country name mapping\n",
    "data['CountryCode'] = data['Variable'].map(lambda x: x.lstrip('BZN_'))\n",
    "data = pd.merge(data, data_dict, on=\"CountryCode\")\n",
    "data = data.drop(['Variable', 'CountryCode'], axis=1)\n",
    "\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of missing data\n",
    "\n",
    "The assumption has been made that the present values of $0.00$ in the data also qualify as missing values. Originally, the function also checked information about TotalLoad_Forecast_MW. Currently, these code sections are commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>number_of_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2016-09-21</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>2018-06-03</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>2020-11-21</td>\n",
       "      <td>2020-11-23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>2021-04-22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-10-21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>2018-07-25</td>\n",
       "      <td>2018-07-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>France</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>2015-04-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>France</td>\n",
       "      <td>2015-11-18</td>\n",
       "      <td>2015-11-19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2015-09-18</td>\n",
       "      <td>2015-09-19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lithuania</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lithuania</td>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lithuania</td>\n",
       "      <td>2016-03-04</td>\n",
       "      <td>2016-03-05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lithuania</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2021-08-07</td>\n",
       "      <td>2021-08-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Slovenia</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>2018-03-20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Spain</td>\n",
       "      <td>2015-04-14</td>\n",
       "      <td>2015-04-15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2015-12-12</td>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>2019-01-16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           country start_date   end_date  number_of_days\n",
       "0          Austria 2017-12-30 2017-12-31               2\n",
       "1          Croatia 2018-01-05 2018-01-06               2\n",
       "2           Cyprus 2015-01-01 2016-09-21             630\n",
       "3           Cyprus 2018-06-03 2018-06-07               5\n",
       "4           Cyprus 2019-03-03 2019-03-04               2\n",
       "5           Cyprus 2019-06-08 2019-07-23              46\n",
       "6           Cyprus 2020-03-13 2020-04-05              24\n",
       "7           Cyprus 2020-04-07 2020-04-09               3\n",
       "8           Cyprus 2020-07-23 2020-07-27               5\n",
       "9           Cyprus 2020-07-28 2020-08-04               8\n",
       "10          Cyprus 2020-11-21 2020-11-23               3\n",
       "11          Cyprus 2021-04-20 2021-04-22               3\n",
       "12  Czech Republic 2016-11-11 2016-11-14               4\n",
       "13         Denmark 2017-10-20 2017-10-21               2\n",
       "14         Denmark 2018-07-25 2018-07-26               2\n",
       "15          France 2015-04-25 2015-04-26               2\n",
       "16          France 2015-11-18 2015-11-19               2\n",
       "17         Ireland 2015-09-18 2015-09-19               2\n",
       "18         Ireland 2016-04-12 2016-04-13               2\n",
       "19       Lithuania 2015-01-03 2015-01-04               2\n",
       "20       Lithuania 2015-01-19 2015-01-20               2\n",
       "21       Lithuania 2016-03-04 2016-03-05               2\n",
       "22       Lithuania 2017-12-30 2018-01-02               4\n",
       "23      Luxembourg 2019-01-03 2019-01-04               2\n",
       "24      Luxembourg 2019-01-31 2019-02-06               7\n",
       "25         Romania 2015-01-01 2015-01-05               5\n",
       "26         Romania 2018-05-22 2018-05-23               2\n",
       "27         Romania 2021-08-07 2021-08-09               3\n",
       "28        Slovenia 2018-03-19 2018-03-20               2\n",
       "29           Spain 2015-04-14 2015-04-15               2\n",
       "30          Sweden 2015-12-12 2015-12-13               2\n",
       "31          Sweden 2019-01-15 2019-01-16               2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>number_of_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lithuania</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Romania</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>France</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Slovenia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Spain</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           country  number_of_days\n",
       "0           Cyprus             729\n",
       "1        Lithuania              10\n",
       "2          Romania              10\n",
       "3       Luxembourg               9\n",
       "4   Czech Republic               4\n",
       "5          Denmark               4\n",
       "6           France               4\n",
       "7          Ireland               4\n",
       "8           Sweden               4\n",
       "9          Austria               2\n",
       "10         Croatia               2\n",
       "11        Slovenia               2\n",
       "12           Spain               2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_missing_value_date_ranges(dataframe):\n",
    "    dataframe['Timestamp'] = pd.to_datetime(dataframe['Timestamp'])\n",
    "\n",
    "    # Creation the resulting DataFrame.\n",
    "    result = []\n",
    "\n",
    "    # Iteration over unique countries.\n",
    "    for country in dataframe['Country'].unique():\n",
    "        country_data = dataframe[dataframe[\"Country\"] == country][[\"Timestamp\", \"TotalLoad_Actual_MW\"]]  # [[\"Timestamp\", \"TotalLoad_Forecast_MW\", \"TotalLoad_Actual_MW\"]]\n",
    "        country_data['Timestamp'] = pd.to_datetime(country_data['Timestamp'])\n",
    "\n",
    "        # Aggregation data to full days and sorting.\n",
    "        agg_df = country_data.resample('D', on='Timestamp').sum().reset_index()\n",
    "\n",
    "        for metric in [\"TotalLoad_Actual_MW\"]:  #  [\"TotalLoad_Forecast_MW\", \"TotalLoad_Actual_MW\"]\n",
    "            start_date = None\n",
    "            end_date = None\n",
    "\n",
    "            for index, row in agg_df.iterrows():\n",
    "                if row[metric] == 0.00:\n",
    "                    if start_date is None:\n",
    "                        start_date = row['Timestamp']\n",
    "                elif start_date is not None:\n",
    "                    end_date = row['Timestamp']\n",
    "                    number_of_days = (end_date - start_date).days + 1\n",
    "                    result.append({'country': country, 'metric': metric, 'start_date': start_date, 'end_date': end_date, 'number_of_days': number_of_days})\n",
    "                    start_date = None\n",
    "                    end_date = None\n",
    "            \n",
    "            # Handling missing end_date - if we have reached the last record\n",
    "            if end_date is None and start_date is not None:\n",
    "                end_date = agg_df['Timestamp'].iloc[-1]\n",
    "                number_of_days = (end_date - start_date).days + 1\n",
    "                result.append({'country': country, 'metric': metric, 'start_date': start_date, 'end_date': end_date, 'number_of_days': number_of_days})\n",
    "\n",
    "    missing_value_date_ranges = pd.DataFrame(result)\n",
    "    missing_value_date_ranges = missing_value_date_ranges.sort_values(by=['country', 'metric']).reset_index(drop=True)\n",
    "\n",
    "    missing_value_date_ranges.drop(columns=['metric'], inplace=True)  # This line should be removed if we want to obtain data regarding TotalLoad_Forecast_MW\n",
    "    \n",
    "    return missing_value_date_ranges\n",
    "\n",
    "missing_value_date_ranges = find_missing_value_date_ranges(data)\n",
    "display(missing_value_date_ranges)\n",
    "\n",
    "missing_days_per_country = missing_value_date_ranges.groupby([\"country\"])[\"number_of_days\"].sum().sort_values(ascending=False).reset_index()  # groupby([\"country\", \"metric\"])[\"number_of_days\"].sum().sort_values(ascending=False).reset_index()\n",
    "display(missing_days_per_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_date_ranges['start_date'] = missing_value_date_ranges['start_date'].dt.date\n",
    "missing_value_date_ranges['end_date'] = missing_value_date_ranges['end_date'].dt.date\n",
    "\n",
    "missing_value_date_ranges.style.hide(axis = 0).to_latex(os.path.join(tables_output_folder, \"tab_00.tex\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_days_per_country.style.hide(axis = 0).to_latex(os.path.join(tables_output_folder, \"tab_01.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "* For each country, measurements start on **2015-01-01** and end on **2021-08-30**.\n",
    "* **Frequency of measurements**:\n",
    "  * In most of the surveyed countries, measurements were taken hourly, \n",
    "  * in five countries (Austria, Hungary, Germany, Luxembourg, Romania) every 15 minutes, \n",
    "  * in two (Ireland, Cyprus) every half an hour.\n",
    "* **Information about specific countries**:\n",
    "  * Cyprus:\n",
    "    * Lack of data:\n",
    "        * **TotalLoad_Actual_MW**:\n",
    "            * from 2015-01-01 00:00:00 to 2016-09-21 00:00:00\n",
    "    * Generally, the data for Cyprus is:\n",
    "        * from 2016-09-21 00:00:00 to 2018-01-16 22:00:00 (),\n",
    "        * from 2015-07-24 21:30:00 to 2017-10-09 21:00:00\n",
    "          and from 2017-10-10 21:30:00 to 2018-01-16 22:00:00 (**TotalLoad_Forecast_MW**),\n",
    "        * 0.00 from 2018-01-10 11:00:00 to 2018-01-16 22:00:00 (**TotalLoad_Forecast_MW**).\n",
    "  * Romania - there are fewer measurements, **need to check why!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation (part 2 - weekly aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prepared = data.set_index('Timestamp')\n",
    "\n",
    "def remove_first_last(group):\n",
    "    return group.iloc[1:-1]\n",
    "\n",
    "# Domyślnie w pandas tydzień jest definiowany jako tydzień kalendarzowy, który rozpoczyna się od poniedziałku i kończy się w niedzielę.\n",
    "# Jeśli tydzień jest częściowo w jednym roku i częściowo w drugim, domyślnie będzie on przypisywany do roku, w którym większość dni tygodnia \n",
    "# przypada na ten rok.\n",
    "weekly_data = data_prepared.groupby('Country')[['TotalLoad_Actual_MW']].resample('W').sum().reset_index()\n",
    "weekly_data = weekly_data.rename(columns={'Timestamp': 'Date'})\n",
    "weekly_data = weekly_data.groupby('Country').apply(remove_first_last).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>TotalLoad_Actual_MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>4345870.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>5067420.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>4607080.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>4781652.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2015-02-08</td>\n",
       "      <td>5298053.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country       Date  TotalLoad_Actual_MW\n",
       "0  Austria 2015-01-11           4345870.00\n",
       "1  Austria 2015-01-18           5067420.00\n",
       "2  Austria 2015-01-25           4607080.00\n",
       "3  Austria 2015-02-01           4781652.00\n",
       "4  Austria 2015-02-08           5298053.00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots\n",
    "#### _TotalLoad_Actual_MW per country **before imputation**._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = weekly_data['Country'].unique()\n",
    "\n",
    "for country in country_list:\n",
    "    electricity_consumption_per_country = weekly_data[weekly_data['Country'] == country].copy()\n",
    "    electricity_consumption_per_country['Date'] = pd.to_datetime(electricity_consumption_per_country['Date'])\n",
    "    \n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.title(f\"Actual Electricity Consumption in Terawatts for Country: {country}\", fontsize=16)\n",
    "    \n",
    "    formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "    formatter.set_scientific(False)\n",
    "    formatter.set_powerlimits((-6, 6))\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    \n",
    "    plt.plot(electricity_consumption_per_country[\"Date\"], electricity_consumption_per_country[\"TotalLoad_Actual_MW\"], color='steelblue')\n",
    "    \n",
    "    plt.xlim(electricity_consumption_per_country[\"Date\"].iloc[0], electricity_consumption_per_country[\"Date\"].iloc[-1])\n",
    "    \n",
    "    ticks = plt.gca().get_yticks()\n",
    "    tick_labels = [f'{int(tick) / 1000000:.1f}' for tick in ticks]\n",
    "    plt.gca().yaxis.set_major_locator(ticker.FixedLocator(ticks))\n",
    "    plt.gca().set_yticklabels(tick_labels)\n",
    "\n",
    "    output_file_path = os.path.join(images_output_folder, f\"actual_electricity_consumption_{country}.jpeg\")\n",
    "    if not os.path.exists(output_file_path):\n",
    "        plt.savefig(output_file_path)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "\n",
    "Imputation was performed using a weighted average with a 7-day window.\n",
    "\n",
    "Currently, due to a significant amount of missing data for Cyprus, I am refraining from performing imputation for this country. This method is not efficient for Cyprus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejność czynności przy imputacji danych:\n",
    "- zamiana wartości 0 na NA w oryginalnych danych\n",
    "- imputacja danych na poziomie oryginalnych danych\n",
    "     * imputację przeprowadzamy jako średnia z ostatnich 30 obserwacji tego samego typu (ta sama godzina i dzień tego samego typu)\n",
    "     * imputację wykonujemy sekwencyjnie zgodnie z kierunkiem czasu\n",
    "- agregacja danych do tygodni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data_list = []\n",
    "\n",
    "for country in data['Country'].unique():\n",
    "    country_data = data[data[\"Country\"] == country][[\"Timestamp\", \"TotalLoad_Actual_MW\"]]\n",
    "    country_data['Timestamp'] = pd.to_datetime(country_data['Timestamp'])\n",
    "    \n",
    "    # Aggregation data to full days and sorting.\n",
    "    agg_df = country_data.resample('D', on='Timestamp').sum().reset_index()\n",
    "    \n",
    "    # Replacing values of 0.00 with null values\n",
    "    agg_df['TotalLoad_Actual_MW'].replace(0.00, pd.NA, inplace=True)\n",
    "    agg_df['TotalLoad_Actual_MW'] = pd.to_numeric(agg_df['TotalLoad_Actual_MW'], errors='coerce')\n",
    "    \n",
    "    window_size = 30\n",
    "\n",
    "    # Imputing missing values using a moving average\n",
    "    agg_df['TotalLoad_Imputed_MW'] = agg_df['TotalLoad_Actual_MW'].fillna(agg_df['TotalLoad_Actual_MW'].rolling(window=window_size, min_periods=1, center=True).mean())\n",
    "\n",
    "    agg_df['Country'] = country\n",
    "    imputed_data_list.append(agg_df)\n",
    "\n",
    "daily_imputed_data = pd.concat(imputed_data_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the index to 'Timestamp'.\n",
    "daily_imputed_data.set_index('Timestamp', inplace=True)\n",
    "\n",
    "# Resampling and grouping by weeks\n",
    "weekly_imputed_data = daily_imputed_data.groupby('Country')[['TotalLoad_Actual_MW', 'TotalLoad_Imputed_MW']].resample('W').sum().reset_index()  # weekly_data = data_prep.groupby('Country')[['TotalLoad_Forecast_MW', 'TotalLoad_Actual_MW']].resample('W').sum().reset_index()  # version with TotalLoad_Forecast_MW\n",
    "weekly_imputed_data = weekly_imputed_data.rename(columns={'Timestamp': 'Date'})\n",
    "weekly_imputed_data = weekly_imputed_data.groupby('Country').apply(remove_first_last).reset_index(drop=True)\n",
    "weekly_imputed_data = weekly_imputed_data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TotalLoad_Actual_MW per country **after imputation**._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = weekly_imputed_data['Country'].unique()\n",
    "for country in country_list:\n",
    "    electricity_consumption_per_country = weekly_imputed_data[weekly_imputed_data['Country'] == country]\n",
    "    electricity_consumption_per_country = electricity_consumption_per_country.reset_index(drop=True)\n",
    "    electricity_consumption_per_country.drop(columns=\"index\", inplace=True)\n",
    "\n",
    "    electricity_consumption_per_country = weekly_imputed_data[weekly_imputed_data['Country'] == country].copy()\n",
    "    electricity_consumption_per_country['Date'] = pd.to_datetime(electricity_consumption_per_country['Date'])\n",
    "    \n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.title(f\"Imputed Electricity Consumption in Terawatts for Country: {country}\", fontsize=16)\n",
    "    \n",
    "    formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "    formatter.set_scientific(False)\n",
    "    formatter.set_powerlimits((-6, 6))\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    \n",
    "    plt.plot(electricity_consumption_per_country[\"Date\"], electricity_consumption_per_country[\"TotalLoad_Actual_MW\"], color='firebrick', label='Actual')\n",
    "    plt.plot(electricity_consumption_per_country[\"Date\"], electricity_consumption_per_country[\"TotalLoad_Imputed_MW\"], color='steelblue', label='Imputed')\n",
    "    \n",
    "    plt.xlim(electricity_consumption_per_country[\"Date\"].iloc[0], electricity_consumption_per_country[\"Date\"].iloc[-1])\n",
    "    plt.legend()\n",
    "    \n",
    "    ticks = plt.gca().get_yticks()\n",
    "    tick_labels = [f'{int(tick) / 1000000:.1f}' for tick in ticks]\n",
    "    plt.gca().yaxis.set_major_locator(ticker.FixedLocator(ticks))\n",
    "    plt.gca().set_yticklabels(tick_labels)\n",
    "\n",
    "    output_file_path = os.path.join(images_output_folder, f\"imputed_electricity_consumption_{country}.jpeg\")\n",
    "    if not os.path.exists(output_file_path):\n",
    "        plt.savefig(output_file_path)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final data preparation for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_the_model = weekly_imputed_data[['Country', 'Date', 'TotalLoad_Imputed_MW']]\n",
    "data_for_the_model.loc[:, 'Date'] = pd.to_datetime(data_for_the_model['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y, y_pred):\n",
    "    mape = np.mean(np.abs((y - y_pred)/y))*100\n",
    "    return round(mape, 2)\n",
    "\n",
    "def ME(y, y_pred):\n",
    "    me = np.mean(y_pred - y)\n",
    "    return round(me, 2)\n",
    "\n",
    "def RMSE(MSE):\n",
    "    rmse = math.sqrt(MSE)\n",
    "    return round(rmse, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching for optimal parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **sarima_split_best_params_search_fit_predict_plot()** function was employed to discover the optimal parameters for SARIMA models for each country, as well as to evaluate the model performance using the selected parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dlaczego nie wykorzystać istniejących bibliotek `pmdarima`, np. auto.arima()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sarima_split_best_params_search_fit_predict_plot(country_name, data):\n",
    "    \n",
    "#     dataset = data.values\n",
    "#     train_data = data[data.index <= '2019-12-31']\n",
    "#     test_data = data[data.index >= '2020-01-01']\n",
    "    \n",
    "#     p = range(0, 2)\n",
    "#     d = range(0, 2)\n",
    "#     q = range(0, 2)\n",
    "#     P = range(0, 2)\n",
    "#     D = range(1, 2)\n",
    "#     Q = range(0, 2)\n",
    "#     s = 12\n",
    "\n",
    "#     best_aic = float(\"inf\")\n",
    "#     best_params = None\n",
    "\n",
    "#     for p_val in p:\n",
    "#         for d_val in d:\n",
    "#             for q_val in q:\n",
    "#                 for P_val in P:\n",
    "#                     for D_val in D:\n",
    "#                         for Q_val in Q:\n",
    "#                             try:\n",
    "#                                 model = SARIMAX(train_data, order=(p_val, d_val, q_val), seasonal_order=(P_val, D_val, Q_val, s))\n",
    "#                                 fit_model = model.fit()\n",
    "#                                 aic = fit_model.aic\n",
    "#                                 if aic < best_aic:\n",
    "#                                     best_aic = aic\n",
    "#                                     best_params = (p_val, d_val, q_val, P_val, D_val, Q_val)\n",
    "#                             except:\n",
    "#                                 continue\n",
    "\n",
    "#     print(f\"Best SARIMA parameters for {country_name}:\", best_params)\n",
    "\n",
    "#     results = {\n",
    "#         'country': country_name,\n",
    "#         'best_params': best_params,\n",
    "#     }\n",
    "    \n",
    "#     try:\n",
    "#         p_val, d_val, q_val, P_val, D_val, Q_val = best_params\n",
    "#         s = 52 \n",
    "#         model = SARIMAX(train_data, order=(p_val, d_val, q_val), seasonal_order=(P_val, D_val, Q_val, s))\n",
    "#         fit_model = model.fit()\n",
    "#         yhat = fit_model.predict(start=len(train_data), end=(len(dataset)-1))\n",
    "    \n",
    "#         pd.DataFrame(yhat).plot()\n",
    "#         data.plot(figsize=(20, 5))\n",
    "#         plt.legend()\n",
    "#     except TypeError:\n",
    "#         pass\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# results_list = []\n",
    "\n",
    "# for country in data_for_the_model['Country'].unique():\n",
    "#     try: \n",
    "#         print(f'Evaluation for country: {country}')\n",
    "#         country_data = data_for_the_model[data_for_the_model['Country'] == country].set_index('Date').asfreq('W')\n",
    "#         results = sarima_split_best_params_search_fit_predict_plot(country, country_data[\"TotalLoad_Imputed_MW\"])\n",
    "#         results_list.append(results)\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred for country {country}: {e}\")\n",
    "\n",
    "# sarima_best_params = {results['country']: results['best_params'] for results in results_list}\n",
    "\n",
    "# sarima_best_params_df = pd.DataFrame(results_list)\n",
    "# display(sarima_best_params_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting, Prediction, Plotting, and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarima_fit_predict_plot_evaluate(country_name, country_data, best_params):\n",
    "    dataset = country_data.values\n",
    "    train_data = country_data[country_data.index <= '2019-12-31']\n",
    "    test_data = country_data[country_data.index >= '2020-01-01']\n",
    "    \n",
    "    s = 52\n",
    "\n",
    "    p_val, d_val, q_val, P_val, D_val, Q_val = best_params\n",
    "\n",
    "    model = SARIMAX(train_data, order=(p_val, d_val, q_val), seasonal_order=(P_val, D_val, Q_val, s))\n",
    "    fit_model = model.fit()\n",
    "    yhat = fit_model.predict(start=len(train_data), end=(len(dataset)-1))\n",
    "\n",
    "    model_filename = f\"sarima_model_{country_name}.pkl\"\n",
    "    model_file_path = os.path.join(models_output_folder, model_filename)\n",
    "\n",
    "    if not os.path.exists(model_file_path):\n",
    "        with open(model_file_path, 'wb') as model_file:\n",
    "            pickle.dump(fit_model, model_file)\n",
    "\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.title(f\"SARIMA Prediction for Electricity Consumption in Terawatts for Country: {country_name}\", fontsize=16)\n",
    "\n",
    "    yhat_df = pd.DataFrame(yhat)\n",
    "    country_data_subset = country_data.iloc[1:-1]  \n",
    "    yhat_df_subset = yhat_df.iloc[1:-1]\n",
    "    \n",
    "    formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "    formatter.set_scientific(False)  \n",
    "    formatter.set_powerlimits((-6, 6))  \n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    \n",
    "    plt.plot(yhat_df_subset, color=\"firebrick\", label='Predicted')\n",
    "    plt.plot(country_data_subset, color='steelblue', label='Actual')\n",
    "    \n",
    "    plt.xlim(country_data_subset.index[0], country_data_subset.index[-1])\n",
    "    plt.legend()\n",
    "    \n",
    "    # Changing the Y-axis value labels from 5000000 to 5.0\n",
    "    plt.gca().set_yticklabels([f'{int(tick) / 1000000:.1f}' for tick in plt.gca().get_yticks()])\n",
    "\n",
    "    output_file_path = os.path.join(images_output_folder, f\"sarima_predictions_{country}.jpeg\")\n",
    "    if not os.path.exists(output_file_path):\n",
    "        plt.savefig(output_file_path)\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    MAPE_metric = MAPE(test_data, yhat)\n",
    "    ME_metric = ME(test_data, yhat)\n",
    "    MAE_metric = round(mean_absolute_error(test_data, yhat), 2)\n",
    "    MSE_metric = round(mean_squared_error(test_data, yhat), 2)\n",
    "    RMSE_metric = RMSE(MSE_metric)\n",
    "\n",
    "    results = {\n",
    "        'model': 'sarima',\n",
    "        'country': country_name,\n",
    "        'mape': MAPE_metric,\n",
    "        'me': ME_metric,\n",
    "        'mae': MAE_metric,\n",
    "        'mse': MSE_metric,\n",
    "        'rmse': RMSE_metric\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Dictionary of best SARIMA parameters obtained using sarima_split_best_params_search_fit_predict_plot() function.\n",
    "sarima_best_params = {\n",
    "    \"Austria\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Croatia\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Cyprus\": (1, 1, 1, 0, 1, 1),\n",
    "    \"Czech Republic\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Denmark\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Estonia\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Finland\": (0, 1, 0, 1, 1, 1),\n",
    "    \"France\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Germany\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Greece\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Hungary\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Ireland\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Italy\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Latvia\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Lithuania\": (0, 1, 1, 1, 1, 1),\n",
    "    \"Luxembourg\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Poland\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Portugal\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Romania\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Slovakia\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Slovenia\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Spain\": (0, 1, 0, 1, 1, 1),\n",
    "    \"Sweden\": (0, 1, 0, 1, 1, 1)\n",
    "}\n",
    "\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for country in data_for_the_model['Country'].unique():\n",
    "    try: \n",
    "        print(f'Evaluation for country: {country}')\n",
    "        country_data = data_for_the_model[data_for_the_model['Country'] == country].set_index('Date').asfreq('W')\n",
    "        best_params = sarima_best_params.get(country)\n",
    "        if best_params is None:\n",
    "            print(f\"No parameters found for country: {country}\")\n",
    "            continue\n",
    "        results = sarima_fit_predict_plot_evaluate(country, country_data[\"TotalLoad_Imputed_MW\"], best_params)\n",
    "        results_list.append(results)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for country {country}: {e}\")\n",
    "\n",
    "sarima_results = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TBATS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching for optimal parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **tbats_split_best_params_search_fit_predict()** function was employed to discover the optimal parameters for TBATS models for each country, as well as to evaluate the model performance using the selected parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbats_best_params = {}\n",
    "\n",
    "# def tbats_split_best_params_search_fit_predict(country_name, data):\n",
    "    \n",
    "#     dataset = data.values\n",
    "#     train_data = data[data.index <= '2019-12-31']\n",
    "#     test_data = data[data.index >= '2020-01-01']\n",
    "    \n",
    "#     seasonal_periods = 52\n",
    "#     use_arma_errors = True\n",
    "#     use_box_cox_options = [True, False]\n",
    "#     use_trend_options = [True, False]\n",
    "#     n_jobs_option = os.cpu_count()\n",
    "#     use_damped_trend = True\n",
    "    \n",
    "#     best_aic = float(\"inf\")\n",
    "#     best_params = None\n",
    "#     best_result_dict = None\n",
    "\n",
    "#     for use_box_cox in use_box_cox_options:\n",
    "#         for use_trend in use_trend_options:\n",
    "#             try:\n",
    "#                 model = TBATS(seasonal_periods=[seasonal_periods],\n",
    "#                               use_arma_errors=use_arma_errors,\n",
    "#                               use_box_cox=use_box_cox,\n",
    "#                               use_trend=use_trend,\n",
    "#                               n_jobs=n_jobs_option,\n",
    "#                               use_damped_trend=use_damped_trend\n",
    "#                              )\n",
    "#                 fit_model = model.fit(train_data)\n",
    "#                 aic = fit_model.aic\n",
    "#                 if aic < best_aic:\n",
    "#                     best_aic = aic\n",
    "#                     best_params = (\n",
    "#                         seasonal_periods, \n",
    "#                         use_arma_errors, \n",
    "#                         use_box_cox,\n",
    "#                         use_trend, \n",
    "#                         n_jobs_option,\n",
    "#                         use_damped_trend\n",
    "#                         )\n",
    "#                     best_result_dict = {\n",
    "#                     \"country\": country_name,\n",
    "#                     \"seasonal_period\": seasonal_periods,\n",
    "#                     \"use_arma_errors\": use_arma_errors,\n",
    "#                     \"use_box_cox\": use_box_cox,\n",
    "#                     \"use_trend\": use_trend,\n",
    "#                     \"use_damped_trend\": use_damped_trend\n",
    "#                 }\n",
    "#             except:\n",
    "#                 continue\n",
    "\n",
    "#     tbats_best_params[country_name] = best_result_dict\n",
    "\n",
    "#     print(f'Best params for country {country_name}: {best_params}')\n",
    "    \n",
    "#     results = {\n",
    "#         'country': country_name,\n",
    "#         'best_params': best_params,\n",
    "#     }\n",
    "    \n",
    "#     return(results)\n",
    "\n",
    "# results_list = []\n",
    "\n",
    "# for country in data_for_the_model['Country'].unique():\n",
    "#     try: \n",
    "#         print(f'Evaluation for country: {country}')\n",
    "#         country_data = data_for_the_model[data_for_the_model['Country'] == country].set_index('Date').asfreq('W')\n",
    "#         results = tbats_split_best_params_search_fit_predict(country, country_data[\"TotalLoad_Imputed_MW\"])\n",
    "#         results_list.append(results)\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred for country {country}: {e}\")\n",
    "\n",
    "# tbats_best_params = {results['country']: results['best_params'] for results in results_list}\n",
    "\n",
    "# tbats_best_params_df = pd.DataFrame(results_list)\n",
    "# display(tbats_best_params_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting, Prediction, Plotting, and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tbats_fit_predict_plot_evaluate(country_name, country_data, best_params):\n",
    "\n",
    "    dataset = country_data.values\n",
    "    train_data = country_data[country_data.index <= '2019-12-31']\n",
    "    test_data = country_data[country_data.index >= '2020-01-01']\n",
    "\n",
    "    (\n",
    "    seasonal_period, \n",
    "    use_arma_errors, \n",
    "    use_box_cox,\n",
    "    use_trend, \n",
    "    n_jobs_option,\n",
    "    use_damped_trend\n",
    "    ) = best_params\n",
    "    \n",
    "    model = TBATS(seasonal_periods=[seasonal_period],\n",
    "                                    use_arma_errors=use_arma_errors,\n",
    "                                    use_box_cox=use_box_cox,\n",
    "                                    use_trend=use_trend,\n",
    "                                    n_jobs=n_jobs_option,\n",
    "                                    use_damped_trend=use_damped_trend\n",
    "                                    )\n",
    "    fit_model = model.fit(train_data)\n",
    "    yhat = fit_model.forecast(steps=len(test_data))\n",
    "\n",
    "    model_filename = f\"tbats_model_{country_name}.pkl\"\n",
    "    model_file_path = os.path.join(models_output_folder, model_filename)\n",
    "\n",
    "    if not os.path.exists(model_file_path):\n",
    "        with open(model_file_path, 'wb') as model_file:\n",
    "            pickle.dump(fit_model, model_file)\n",
    "\n",
    "    start_date = '2020-01-07'\n",
    "    end_date = '2021-09-05'\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='7D')\n",
    "\n",
    "    yhat_df = pd.DataFrame(yhat, index=date_range)\n",
    "    yhat_df_subset = yhat_df.iloc[1:-1]\n",
    "\n",
    "    country_data_subset = country_data.iloc[1:-1] \n",
    "\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.title(f\"TBATS Prediction for Electricity Consumption in Terawatts for Country: {country_name}\", fontsize=16)\n",
    "    \n",
    "    formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "    formatter.set_scientific(False)\n",
    "    formatter.set_powerlimits((-6, 6))\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    \n",
    "    plt.plot(yhat_df_subset, color=\"firebrick\", label='Predicted')\n",
    "    plt.plot(country_data_subset, color='steelblue', label='Actual')\n",
    "    \n",
    "    plt.xlim(country_data_subset.index[0], country_data_subset.index[-1])\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.gca().set_yticklabels([f'{int(tick) / 1000000:.1f}' for tick in plt.gca().get_yticks()])\n",
    "\n",
    "    output_file_path = os.path.join(images_output_folder, f\"tbats_predictions_{country}.jpeg\")\n",
    "    if not os.path.exists(output_file_path):\n",
    "        plt.savefig(output_file_path)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "    MAPE_metric = MAPE(test_data, yhat)\n",
    "    ME_metric = ME(test_data, yhat)\n",
    "    MAE_metric = round(mean_absolute_error(test_data, yhat), 2)\n",
    "    MSE_metric = round(mean_squared_error(test_data, yhat), 2)\n",
    "    RMSE_metric = RMSE(MSE_metric)\n",
    "\n",
    "    results = {\n",
    "        'model': 'tbats',\n",
    "        'country': country_name,\n",
    "        'mape': MAPE_metric,\n",
    "        'me': ME_metric,\n",
    "        'mae': MAE_metric,\n",
    "        'mse': MSE_metric,\n",
    "        'rmse': RMSE_metric\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Dictionary of best TBATS parameters obtained using tbats_split_best_params_search_fit_predict() function\n",
    "tbats_best_params = {\n",
    "    \"Austria\": (52, True, False, True, 4, True),\n",
    "    \"Croatia\": (52, True, True, False, 4, True),\n",
    "    \"Cyprus\": (52, True, True, False, 4, True),\n",
    "    \"Czech Republic\": (52, True, True, True, 4, True),\n",
    "    \"Denmark\": (52, True, True, False, 4, True),\n",
    "    \"Estonia\": (52, True, True, False, 4, True),\n",
    "    \"Finland\": (52, True, True, False, 4, True),\n",
    "    \"France\": (52, True, True, True, 4, True),\n",
    "    \"Germany\": (52, True, False, False, 4, True),\n",
    "    \"Greece\": (52, True, True, False, 4, True),\n",
    "    \"Hungary\": (52, True, False, False, 4, True),\n",
    "    \"Ireland\": (52, True, False, False, 4, True),\n",
    "    \"Italy\": (52, True, True, False, 4, True),\n",
    "    \"Latvia\": (52, True, True, False, 4, True),\n",
    "    \"Lithuania\": (52, True, True, True, 4, True),\n",
    "    \"Luxembourg\": (52, True, False, False, 4, True),\n",
    "    \"Poland\": (52, True, False, False, 4, True),\n",
    "    \"Portugal\": (52, True, False, False, 4, True),\n",
    "    \"Romania\": (52, True, True, True, 4, True),\n",
    "    \"Slovakia\": (52, True, True, True, 4, True),\n",
    "    \"Slovenia\": (52, True, True, False, 4, True),\n",
    "    \"Spain\": (52, True, True, True, 4, True),\n",
    "    \"Sweden\": (52, True, True, False, 4, True)\n",
    "}\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for country in data_for_the_model['Country'].unique():\n",
    "    try: \n",
    "        print(f'Evaluation for country: {country}')\n",
    "        country_data = data_for_the_model[data_for_the_model['Country'] == country].set_index('Date').asfreq('W')\n",
    "        best_params = tbats_best_params.get(country)\n",
    "        if best_params is None:\n",
    "            print(f\"No parameters found for country: {country}\")\n",
    "            continue\n",
    "        results = tbats_fit_predict_plot_evaluate(country, country_data[\"TotalLoad_Imputed_MW\"], best_params)\n",
    "        results_list.append(results)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for country {country}: {e}\")\n",
    "\n",
    "tbats_results = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting, Prediction, Plotting, and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_fit_predict_plot_evaluate(country_name, country_data):\n",
    "    \n",
    "    dataset = country_data.values\n",
    "    train_data = country_data[country_data.index <= '2019-12-31']\n",
    "    test_data = country_data[country_data.index >= '2020-01-01']\n",
    "    \n",
    "    look_back = 10\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    train_data = scaler.fit_transform(train_data.values.reshape(-1, 1))\n",
    "    test_data_rescaled = scaler.transform(test_data.values.reshape(-1, 1))\n",
    "    \n",
    "    def prepare_data(data, look_back=10):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - look_back):\n",
    "            X.append(data[i:i + look_back])\n",
    "            y.append(data[i + look_back])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    X_train, y_train = prepare_data(train_data, look_back)\n",
    "    X_test, y_test = prepare_data(test_data_rescaled, look_back)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(look_back, 1), return_sequences=True))  # Dodana warstwa LSTM\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', metrics=[\"mape\"], optimizer='adam')\n",
    "    \n",
    "    fit_model = model.fit(X_train, y_train, epochs=500, batch_size=1, verbose=2)\n",
    "\n",
    "    yhat = model.predict(X_test)\n",
    "    predictions_rescaled = scaler.inverse_transform(yhat)\n",
    "    yhat_df = pd.DataFrame(predictions_rescaled, index=test_data.index[look_back:])\n",
    "\n",
    "    model_filename = f\"lstm_model_{country_name}.pkl\"\n",
    "    model_file_path = os.path.join(models_output_folder, model_filename)\n",
    "\n",
    "    if not os.path.exists(model_file_path):\n",
    "        with open(model_file_path, 'wb') as model_file:\n",
    "            pickle.dump(fit_model, model_file)\n",
    "\n",
    "    country_data_subset = country_data.iloc[1:-1] \n",
    "\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.title(f\"LSTM Prediction for Electricity Consumption in Terawatts for Country: {country_name}\", fontsize=16)\n",
    "    \n",
    "    country_data_subset = country_data.iloc[1:-1] \n",
    "    yhat_df_subset = yhat_df.iloc[1:-1]\n",
    "    \n",
    "    formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "    formatter.set_scientific(False)\n",
    "    formatter.set_powerlimits((-6, 6))\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    \n",
    "    plt.plot(yhat_df_subset, color=\"firebrick\", label='Predicted')\n",
    "    plt.plot(country_data_subset, color='steelblue', label='Actual')\n",
    "    \n",
    "    plt.xlim(country_data_subset.index[0], country_data_subset.index[-1])\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.gca().set_yticklabels([f'{int(tick) / 1000000:.1f}' for tick in plt.gca().get_yticks()])\n",
    "\n",
    "    output_file_path = os.path.join(images_output_folder, f\"lstm_predictions_{country}.jpeg\")\n",
    "    if not os.path.exists(output_file_path):\n",
    "        plt.savefig(output_file_path)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "    MAPE_metric = MAPE(test_data.iloc[look_back:], yhat_df)\n",
    "    ME_metric = ME(test_data.iloc[look_back:], yhat_df)\n",
    "    MAE_metric = round(mean_absolute_error(test_data.iloc[look_back:], yhat_df), 2)\n",
    "    MSE_metric = round(mean_squared_error(test_data.iloc[look_back:], yhat_df), 2)\n",
    "    RMSE_metric = RMSE(MSE_metric)\n",
    "\n",
    "    results = {\n",
    "        'model': 'lstm',\n",
    "        'country': country_name,\n",
    "        'mape': MAPE_metric,\n",
    "        'me': ME_metric,\n",
    "        'mae': MAE_metric,\n",
    "        'mse': MSE_metric,\n",
    "        'rmse': RMSE_metric\n",
    "    }\n",
    "    \n",
    "    return fit_model, results\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for country in data_for_the_model['Country'].unique():\n",
    "    try: \n",
    "        print(f'Evaluation for country: {country}')\n",
    "        country_data = data_for_the_model[data_for_the_model['Country'] == country].set_index('Date').asfreq('W')\n",
    "        country_history, country_results = lstm_fit_predict_plot_evaluate(country, country_data[\"TotalLoad_Imputed_MW\"])\n",
    "        locals()[f'history_{country}'] = country_history\n",
    "        results_list.append(country_results)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for country {country}: {e}\")\n",
    "\n",
    "lstm_results = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = pd.concat([sarima_results, tbats_results, lstm_results], ignore_index=True).sort_values(by=['country', 'model'], ascending=[True, True])\n",
    "display(results)\n",
    "\n",
    "evaluation_results.style.hide(axis = 0).to_latex(os.path.join(tables_output_folder, \"tab_02.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mape=history.history['mape']\n",
    "# loss=history.history['loss']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
